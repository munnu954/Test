To fix the error, you need to update the test case code as follows:

```java
import org.junit.jupiter.api.Test;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.client.RestTemplate;

import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.Mockito.*;

public class FlinkApiControllerTest {

    @Test
    void testTriggerJob_Successful() {
        // Create mock RestTemplate
        RestTemplate restTemplate = mock(RestTemplate.class);

        // Set up the expected values
        String jobSubmitUrl = "http://flink-api-url/jars/flink-job-jar-id/run";
        ResponseEntity<String> responseEntity = new ResponseEntity<>("Job triggered", HttpStatus.OK);
        when(restTemplate.postForEntity(eq(jobSubmitUrl), any(), eq(String.class))).thenReturn(responseEntity);

        // Create an instance of FlinkApiController with the mock RestTemplate
        FlinkApiController flinkApiController = new FlinkApiController(restTemplate);

        // Create an instance of SpaceCollector
        SpaceCollector collector = new SpaceCollector();
        collector.setInputFilePath("test.csv");

        // Set the other required input values
        String fileType = ".csv";

        // Call the method being tested
        String result = flinkApiController.triggerJob(collector, fileType);

        // Verify the result
        assertEquals("Job triggered", result);

        // Verify that the RestTemplate method was called with the correct parameters
        verify(restTemplate, times(1)).postForEntity(eq(jobSubmitUrl), any(), eq(String.class));
    }
}
```

In the updated code, we have:

1. Created a mock `RestTemplate` using Mockito to be used in the test.
2. Set up the expected values for the mock `RestTemplate` response using `responseEntity`.
3. Created an instance of `FlinkApiController` with the mock `RestTemplate`.
4. Called the `triggerJob` method of `FlinkApiController` with the required input values.
5. Asserted the result to be "Job triggered".
6. Verified that the `postForEntity` method of the mock `RestTemplate` was called with the correct parameters.

Note: Please make sure you have the necessary dependencies for JUnit 5 and Mockito in your project.





_____________________________________________
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.mockito.Mock;
import org.mockito.MockitoAnnotations;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest;
import org.springframework.boot.test.mock.mockito.MockBean;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.test.context.junit.jupiter.SpringJUnitConfig;
import org.springframework.web.client.HttpClientErrorException;
import org.springframework.web.client.RestTemplate;

import static org.junit.jupiter.api.Assertions.*;
import static org.mockito.ArgumentMatchers.*;
import static org.mockito.Mockito.*;

@SpringJUnitConfig
@WebMvcTest({KafkaInputProducer.class, FlinkApiController.class, KafkaConsumer.class})
class KafkaInputProducerTest {

    @Autowired
    private KafkaInputProducer kafkaInputProducer;

    @Autowired
    private FlinkApiController flinkApiController;

    @Autowired
    private KafkaConsumer kafkaConsumer;

    @MockBean
    private KafkaTemplate<String, Object> kafkaTemplate;

    @MockBean
    private RestTemplate restTemplate;

    @BeforeEach
    void setup() {
        MockitoAnnotations.openMocks(this);
    }

    @Test
    void testWriteMessage_Successful() {
        FileMetadata collector = new FileMetadata();
        when(kafkaTemplate.send(anyString(), any())).thenReturn(null);

        boolean result = kafkaInputProducer.writeMessage(collector);

        assertTrue(result);
        verify(kafkaTemplate, times(1)).send(anyString(), eq(collector));
    }

    @Test
    void testWriteMessage_Failure() {
        FileMetadata collector = new FileMetadata();
        when(kafkaTemplate.send(anyString(), any())).thenThrow(new RuntimeException());

        boolean result = kafkaInputProducer.writeMessage(collector);

        assertFalse(result);
        verify(kafkaTemplate, times(1)).send(anyString(), eq(collector));
    }

    @Test
    void testTriggerJob_Successful() {
        SpaceCollector collector = new SpaceCollector();
        collector.setInputFilePath("test.csv");
        String fileType = ".csv";
        String programArgs = "--input |inputPath|";
        String jobSubmitUrl = "http://flink-api-url/jars/flink-job-jar-id/run";
        ResponseEntity<String> responseEntity = new ResponseEntity<>("Job triggered", HttpStatus.OK);
        when(restTemplate.postForEntity(eq(jobSubmitUrl), any(), eq(String.class))).thenReturn(responseEntity);

        String result = flinkApiController.triggerJob(collector, fileType);

        assertEquals("Job triggered", result);
        verify(restTemplate, times(1)).postForEntity(eq(jobSubmitUrl), any(), eq(String.class));
    }

    @Test
    void testTriggerJob_Failure_HttpClientErrorException() {
        SpaceCollector collector = new SpaceCollector();
        collector.setInputFilePath("test.csv");
        String fileType = ".csv";
        String programArgs = "--input |inputPath|";
        String jobSubmitUrl = "http://flink-api-url/jars/non-existent-jar-id/run";
        HttpClientErrorException exception = new HttpClientErrorException(HttpStatus.NOT_FOUND);
        when(restTemplate.postForEntity(eq(jobSubmitUrl), any(), eq(String.class))).thenThrow(exception);

        String result = flinkApiController.triggerJob(collector, fileType);

        assertEquals("Job is not triggered", result);
        verify(restTemplate, times(1)).postForEntity(eq(jobSubmitUrl), any(), eq(String.class));
    }

    @Test
    void testTriggerJob_Failure_RuntimeException() {
        SpaceCollector collector = new SpaceCollector();
        collector.setInputFilePath("test.csv");
        String fileType = ".csv";
        String programArgs = "--input |inputPath|";
        String jobSubmitUrl = "http://flink-api-url/jars/flink-job-jar-id/run";
        RuntimeException exception = new RuntimeException("Internal Server Error");
        when(restTemplate.postForEntity(eq(jobSubmitUrl), any(), eq(String.class))).thenThrow(exception);

        String result = flinkApiController.triggerJob(collector, fileType);

        assertEquals("Job is not triggered", result);
        verify(restTemplate, times(1)).postForEntity(eq(jobSubmitUrl), any(), eq(String.class));
    }

    @Test
    void testConsume_Successful() throws IOException {
        String data = "{\"inputFilePath\": \"test.csv\"}";
        SpaceCollector spaceCollector = new SpaceCollector();
        spaceCollector.setInputFilePath("test.csv");
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name("test.csv");
        ResponseEntity<String> responseEntity = new ResponseEntity<>("Job triggered", HttpStatus.OK);
        when(kafkaConsumer.validateFile(anyString())).thenReturn(true);
        when(flinkApiController.triggerJob(any(), anyString())).thenReturn("Job triggered");
        when(restTemplate.postForEntity(anyString(), any(), any())).thenReturn(responseEntity);
        when(kafkaConsumer.logMetadata(any(), anyString(), any())).thenReturn(fileMetadata);

        kafkaConsumer.consume(data);

        verify(kafkaConsumer, times(1)).validateFile(eq("test.csv"));
        verify(kafkaConsumer, times(1)).retrieveCsvFile(eq("test.csv"));
        verify(flinkApiController, times(1)).triggerJob(any(), eq(".csv"));
        verify(kafkaConsumer, times(1)).logMetadata(any(), anyString(), any());
        verify(kafkaInputProducer, times(1)).writeMessage(eq(fileMetadata));
        verify(kafkaConsumer, times(1)).writeLogToFile(eq(fileMetadata), anyString());
    }

    @Test
    void testConsume_InvalidInputFile() throws IOException {
        String data = "{\"inputFilePath\": \"non-existent-file.csv\"}";
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name("non-existent-file.csv");
        fileMetadata.setExceptions("Input file path doesn't exists/Invalid file");
        when(kafkaConsumer.validateFile(anyString())).thenReturn(false);
        when(kafkaConsumer.logMetadata(any(), anyString(), any())).thenReturn(fileMetadata);

        kafkaConsumer.consume(data);

        verify(kafkaConsumer, times(1)).validateFile(eq("non-existent-file.csv"));
        verify(kafkaConsumer, times(1)).logMetadata(any(), anyString(), any());
        verify(kafkaConsumer, times(1)).writeLogToFile(eq(fileMetadata), anyString());
    }

    @Test
    void testConsume_Failure_HttpClientErrorException() throws IOException {
        String data = "{\"inputFilePath\": \"test.csv\"}";
        SpaceCollector spaceCollector = new SpaceCollector();
        spaceCollector.setInputFilePath("test.csv");
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name("test.csv");
        HttpClientErrorException exception = new HttpClientErrorException(HttpStatus.NOT_FOUND);
        when(kafkaConsumer.validateFile(anyString())).thenReturn(true);
        when(flinkApiController.triggerJob(any(), anyString())).thenThrow(exception);
        when(kafkaConsumer.logMetadata(any(), anyString(), any())).thenReturn(fileMetadata);

        kafkaConsumer.consume(data);

        verify(kafkaConsumer, times(1)).validateFile(eq("test.csv"));
        verify(kafkaConsumer, times(1)).retrieveCsvFile(eq("test.csv"));
        verify(flinkApiController, times(1)).triggerJob(any(), eq(".csv"));
        verify(kafkaConsumer, times(1)).logMetadata(any(), anyString(), any());
        verify(kafkaInputProducer, times(1)).writeMessage(eq(fileMetadata));
        verify(kafkaConsumer, times(1)).writeLogToFile(eq(fileMetadata), anyString());
    }

    @Test
    void testConsume_Failure_RuntimeException() throws IOException {
        String data = "{\"inputFilePath\": \"test.csv\"}";
        SpaceCollector spaceCollector = new SpaceCollector();
        spaceCollector.setInputFilePath("test.csv");
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name("test.csv");
        RuntimeException exception = new RuntimeException("Internal Server Error");
        when(kafkaConsumer.validateFile(anyString())).thenReturn(true);
        when(flinkApiController.triggerJob(any(), anyString())).thenThrow(exception);
        when(kafkaConsumer.logMetadata(any(), anyString(), any())).thenReturn(fileMetadata);

        kafkaConsumer.consume(data);

        verify(kafkaConsumer, times(1)).validateFile(eq("test.csv"));
        verify(kafkaConsumer, times(1)).retrieveCsvFile(eq("test.csv"));
        verify(flinkApiController, times(1)).triggerJob(any(), eq(".csv"));
        verify(kafkaConsumer, times(1)).logMetadata(any(), anyString(), any());
        verify(kafkaInputProducer, times(1)).writeMessage(eq(fileMetadata));
        verify(kafkaConsumer, times(1)).writeLogToFile(eq(fileMetadata), anyString());
    }
}