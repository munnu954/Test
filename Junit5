SpaceCollector.java model class:

@Data
@NoArgsConstructor
@AllArgsConstructor
@ToString
public class SpaceCollector {
    private String fileName;
    private LocalDateTime dateReceived;
    private LocalDateTime dateProcessed;
    private int numOfRecordsInFile;
    private int numOfRecordsProcessed;
    private int numOfRecordsFailed;
    private String jobStatus;
    private String jobId;
    private String jarId;
    private List<String> exceptions;
}

JsonUtils.java class:

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;

public class JsonUtils {
    private static final ObjectMapper mapper = new ObjectMapper();
    
    public static String convertSpaceCollectorToJson(SpaceCollector spaceCollector) throws JsonProcessingException {
        return mapper.writeValueAsString(spaceCollector);
    }

    public static SpaceCollector convertJsonToSpaceCollector(String json) throws JsonProcessingException {
        return mapper.readValue(json, SpaceCollector.class);
    }
}

KafkaProducer.java:

@Service
public class KafkaProducer {
    private static final Logger Logger = LoggerFactory.getLogger(KafkaProducer.class);

    @Value("${spring.kafka.producer.topic-name}")
    private String topicName;

    private final KafkaTemplate<String, String> kafkaTemplate;

    @Autowired
    public KafkaProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendMessage(SpaceCollector spaceCollector) {
        try {
            String json = JsonUtils.convertSpaceCollectorToJson(spaceCollector);
            Logger.info(String.format("Message sent: %s", json));
            kafkaTemplate.send(topicName, json);
        } catch (JsonProcessingException e) {
            Logger.error("Error serializing SpaceCollector object to JSON", e);
        }
    }
}

KafkaController.java:

@RestController
public class KafkaController {
    private final KafkaProducer kafkaProducer;

    @Autowired
    public KafkaController(KafkaProducer kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }

    @PostMapping("/kafkaPush")
    public ResponseEntity<String> sendMessage(@RequestBody SpaceCollector spaceCollector) {
        kafkaProducer.sendMessage(spaceCollector);
        return ResponseEntity.ok("Message sent successfully");
    }
}

FlinkApiController.java:

@Service
public class FlinkApiController {
    private final RestTemplate restTemplate;
    private final HttpHeaders headers;
    private static final Logger LOGGER = LoggerFactory.getLogger(FlinkApiController.class);

    @Value("${flink.api.url}")
    private String flinkApiUrl;

    @Value("${flink.job.csv.jarid}")
    private String flinkJobCsvJarid;

    @Value("${flink.job.csv.program-args}")
    private String flinkJobCsvProgramArgs;

    @Value("${flink.job.txt.jarid}")
    private String flinkJobTxtJarid;

    @Value("${flink.job.txt.program-args}")
    private String flinkJobTxtProgramArgs;

    @Value("${flink.job.xml.jarid}")
    private String flinkJobXmlJarid;

    @Value("${flink.job.xml.program-args}")
    private String flinkJobXmlProgramArgs;

    @Autowired
    public FlinkApiController(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
        this.headers = new HttpHeaders();
        this.headers.setContentType(MediaType.APPLICATION_JSON);
    }
    
    public void triggerJob(SpaceCollector spaceCollector, String fileType) {
        LOGGER.info("Triggering job...");
        String jobSubmitUrl = null;
        JSONObject requestBody = new JSONObject();

        if(fileType.equalsIgnoreCase(".csv")) {
            requestBody.put("programArgs", flinkJobCsvProgramArgs.replace("input", spaceCollector.getFileName()));
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobCsvJarid + "/run";
        }
        else if(fileType.equalsIgnoreCase(".txt")) {
            requestBody.put("programArgs", flinkJobTxtProgramArgs.replace("|input|", spaceCollector.getFileName()));
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobTxtJarid + "/run";
        }
        else if(fileType.equalsIgnoreCase(".xml")) {
            requestBody.put("programArgs", flinkJobXmlProgramArgs.replace("|filePath|", spaceCollector.getFileName()));
            requestBody.put("primaryKey", "");
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobXmlJarid + "/run";
        }

        HttpEntity<String> request = new HttpEntity<>(requestBody.toString(), headers);
        ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);

        if (response.getStatusCode() != HttpStatus.OK) {
            publishFailureMessage(spaceCollector, response.getBody());
        }
    }

    public void publishFailureMessage(SpaceCollector spaceCollector, String errorMessage) {
        LOGGER.error("Job submission failed");
        LOGGER.error("Error Message: {}", errorMessage);

        spaceCollector.setDateProcessed(LocalDateTime.now());
        spaceCollector.setNumOfRecordsProcessed(0);
        spaceCollector.setNumOfRecordsFailed(spaceCollector.getNumOfRecordsInFile());
        spaceCollector.setJobStatus("Failure");
        spaceCollector.setExceptions(Arrays.asList(errorMessage.split("\n")));

        KafkaProducer.sendMessage(spaceCollector);
    }
}

KafkaConsumer.java class:

@Service
public class KafkaConsumer {
    private static final Logger LOGGER = LoggerFactory.getLogger(KafkaConsumer.class);

    private final FlinkApiController flinkApiController;
    private final KafkaProducer kafkaProducer;

    @Value("${file.destination}")
    private String destinationFolderPath;

    @Value("${file.txtsource}")
    private String txtSourceFilePath;

    @Autowired
    public KafkaConsumer(FlinkApiController flinkApiController, KafkaProducer kafkaProducer) {
        this.flinkApiController = flinkApiController;
        this.kafkaProducer = kafkaProducer;
    }

    @KafkaListener(topics = "${spring.kafka.producer.topic-name}", groupId = "${spring.kafka.consumer.group-id}")
    public void consume(String jsonData) {
        try {
            SpaceCollector spaceCollector = JsonUtils.convertJsonToSpaceCollector(jsonData);
            LOGGER.info(String.format("Message received -> %s", spaceCollector));

            if (!validateInputTopic()) {
                String errorMessage = "Input topic not accessible";
                LOGGER.error(errorMessage);
                spaceCollector.setExceptions(Arrays.asList(errorMessage));
                kafkaProducer.sendMessage(spaceCollector);
                writeToLogFile(errorMessage);
                return;
            }

            String fileType = getExtension(spaceCollector.getFileName());
            flinkApiController.triggerJob(spaceCollector, fileType);
        } catch (Exception e) {
            String errorMessage = "Error processing message";
            LOGGER.error(errorMessage, e);

            SpaceCollector spaceCollector = new SpaceCollector();
            spaceCollector.setExceptions(Arrays.asList(errorMessage, e.toString()));
            kafkaProducer.sendMessage(spaceCollector);
            writeToLogFile(e.getMessage());
        }
    }

    private boolean validateInputTopic() {
        // Check accessibility of input topic
        return true;
    }

    private void writeToLogFile(String message) {
        // Write message to log file in shared location
    }

    private String getExtension(String filename) {
        if (filename != null && filename.contains(".")) {
            return filename.substring(filename.lastIndexOf("."));
        }
        return null;
    }
}