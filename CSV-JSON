@MockBean
    private KafkaAuditProducer kafkaAuditProducer;

    @Autowired
    private FlinkApiController flinkApiController;

    @Test
    public void testTriggerJobSuccess() throws Exception {
        UnifiedAuditMessage auditMsg = new UnifiedAuditMessage();
        auditMsg.setInputFilePath("test.csv");
        String fileType = ".csv";

        when(kafkaAuditProducer.createMessageAndLog(anyString(), anyString(), anyInt(), anyString(), anyString(), anyString(), anyString(), anyInt(), anyInt(), anyInt(), anyString(), anyString(), anyString(), anyList(), anyString()))
                .thenReturn("Message sent successfully");

        String result = flinkApiController.triggerJob(auditMsg, fileType);

        verify(kafkaAuditProducer, times(1)).createMessageAndLog(eq(auditMsg.getInputFilePath()), eq(auditMsg.getUrl()), eq(auditMsg.getPort()), eq(auditMsg.getOutputFilePath()), eq(auditMsg.getDelimiters()), eq(fileType), anyString(), eq(auditMsg.getNo_of_records_in_the_file()), eq(auditMsg.getNo_of_records_processed()), eq(auditMsg.getNo_of_records_failed()), eq(auditMsg.getJob_id()), eq(auditMsg.getJar_id()), eq(auditMsg.getCollector_id()), eq(auditMsg.getExceptions()), eq(JobStatus.FLINK_JOB_SUBMITTED.toString()));
        assertEquals("Job submitted", result);
    }
}
Negative test case for AC2:

java
Download
Copy code
@RunWith(SpringRunner.class)
@SpringBootTest
public class FlinkApiControllerTest {

    @MockBean
    private KafkaAuditProducer kafkaAuditProducer;

    @Autowired
    private FlinkApiController flinkApiController;

    @Test
    public void testTriggerJobFailure() throws Exception {
        UnifiedAuditMessage auditMsg = new UnifiedAuditMessage();
        auditMsg.setInputFilePath("test.csv");
        String fileType = ".csv";

        when(kafkaAuditProducer.createMessageAndLog(anyString(), anyString(), anyInt(), anyString(), anyString(), anyString(), anyString(), anyInt(), anyInt(), anyInt(), anyString(), anyString(), anyString(), anyList(), anyString()))
                .thenReturn("Message sent successfully");

        doThrow(new Exception("Test exception"))
                .when(flinkApiController)
                .updateJobStatus(auditMsg, anyString());

        String result = flinkApiController.triggerJob(auditMsg, fileType);

        verify(kafkaAuditProducer, times(1)).createMessageAndLog(eq(auditMsg.getInputFilePath()), eq(auditMsg.getUrl()), eq(auditMsg.getPort()), eq(auditMsg.getOutputFilePath()), eq(auditMsg.getDelimiters()), eq(fileType), anyString(), eq(auditMsg.getNo_of_records_in_the_file()), eq(auditMsg.getNo_of_records_processed()), eq(auditMsg.getNo_of_records_failed()), eq(auditMsg.getJob_id()), eq(auditMsg.getJar_id()), eq(auditMsg.getCollector_id()), eq(auditMsg.getExceptions()), eq(JobStatus.FLINK_JOB_FAILED.toString()));
        assertEquals("Job is not triggered", result);
    }
}
Note: The above test cases are just examples and might need to be adjusted based on the actual implementation and dependencies of the FlinkApiController class. The @MockBean annotation is used to create mock implementations of the KafkaAuditProducer class, and the when and verify methods are used to set up and verify the behavior of the mocks. The doThrow method is used to simulate an exception being thrown during the updateJobStatus method call.

Is this conversation helpful so far?


People also ask:
Test Case Name: TestSuccessfulTransformationJobSubmission
Test Steps:
Scroll to bottom
Regenerate
Share

New Thread


Web Browsing Mode