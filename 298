

catch (HttpClientErrorException | HttpServerErrorException e) {
    e.printStackTrace();
    LOGGER.error("Error triggering job", e.getMessage());

    if (e.getStatusCode() == HttpStatus.INTERNAL_SERVER_ERROR) {
        FileMetadata metadata = kafkaConsumer.logMetadata(collector, fileType, e);
        kafkaInputProducer.sendFailureMessage(collector, fileType, e);
        kafkaConsumer.writeLogToFile(metadata, destinationFolderPath);
    }
}



M A S:
SpaceCollector.java:

@Data
@NoArgsConstructor
@AllArgsConstructor
@ToString
public class SpaceCollector {

    private Integer id;
    private String url;
    
    @Max(value = 9999, message = "Only 4 digit port number allowed")
    private Integer port;
    
    private String inputFilePath;
    private String outputFilePath;
    private String delimiters;
    private String fileType;

    // Getters and Setters
}


JsonUtils.java:
public class JsonUtils {

    private JsonUtils() {}

    public static String convertSpaceCollectorToJson(SpaceCollector sp) throws JsonProcessingException {
        ObjectWriter ow = new ObjectMapper().writer().withDefaultPrettyPrinter();
        return ow.writeValueAsString(sp);
    }

    public static SpaceCollector convertJsonToSpaceCollector(String data) throws JsonProcessingException {
        ObjectMapper mapper = new ObjectMapper();
        return mapper.readValue(data, SpaceCollector.class);
    }
}

KafkaProducer.java:
@Service
public class KafkaProducer {

    private static final Logger Logger = LoggerFactory.getLogger(KafkaProducer.class);

    private final KafkaTemplate<String, Object> kafkaTemplate;

    @Autowired
    public KafkaProducer(KafkaTemplate<String, Object> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendMessage(SpaceCollector message) {
        Logger.info(String.format("Message sent %s", message));
        kafkaTemplate.send("3459-COLLECTION-REQUEST-QUEUE", message);
    }

    public void sendErrorMessage(String errorMessage) {
        kafkaTemplate.send("3459-COLLECTION-AUDIT-QUEUE", errorMessage);
    }
}

KafkaController.java:
@RestController
public class KafkaController {

    private final KafkaProducer kafkaProducer;

    @Autowired
    public KafkaController(KafkaProducer kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }

    @PostMapping("/kafkaPush")
    public void sendMessage(@RequestBody SpaceCollector message) {
        kafkaProducer.sendMessage(message);
    }
}

FlinkApiController.java:
@Service
public class FlinkApiController {

    private static final Logger LOGGER = LoggerFactory.getLogger(FlinkApiController.class);

    @Value("${flink.api.url}")
    private String flinkApiUrl;

    @Value("${flink.job.csv.jarid}")
    private String flinkJobCsvJarId;

    @Value("${flink.job.csv.program-args}")
    private String flinkJobCsvProgramArgs;

    @Value("${flink.job.txt.jarid}")
    private String flinkJobTxtJarId;

    @Value("${flink.job.txt.program-args}")
    private String flinkJobTxtProgramArgs;

    @Value("${flink.job.xml.jarid}")
    private String flinkJobXmlJarId;

    @Value("${flink.job.xml.program-args}")
    private String flinkJobXmlProgramArgs;

    HttpHeaders headers = new HttpHeaders();

    @Autowired
    private RestTemplate restTemplate;

    public void setRestTemplate(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    @PostMapping("/triggerJob")
    public String triggerJob(SpaceCollector collector) {
        LOGGER.info("TRIGGER JOB");

        String fileExtension = getFileExtension(collector.getInputFilePath());

        if (fileExtension == null) {
            LOGGER.error("Invalid file extension");
            return "Invalid file extension";
        }

        String jobSubmitUrl;
        String programArgs;
        String jarId;

        if (fileExtension.equalsIgnoreCase(".csv")) {
            LOGGER.info("CSV FLINK TRIGGER");
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobCsvJarId + "/run";
            programArgs = flinkJobCsvProgramArgs.replace("input", collector.getInputFilePath());
            jarId = flinkJobCsvJarId;
        } else if (fileExtension.equalsIgnoreCase(".txt")) {
            LOGGER.info("TEXT FLINK TRIGGER");

jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobTxtJarId + "/run";
            programArgs = flinkJobTxtProgramArgs.replace("|input|", collector.getInputFilePath());
            jarId = flinkJobTxtJarId;
        } else if (fileExtension.equalsIgnoreCase(".xml")) {
            LOGGER.info("XML FLINK TRIGGER");
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobXmlJarId + "/run";
            programArgs = flinkJobXmlProgramArgs.replace("|filePath|", collector.getInputFilePath()).replace("|primaryKey|", "");
            jarId = flinkJobXmlJarId;
        } else {
            LOGGER.error("Unsupported file extension");
            return "Unsupported file extension";
        }

        headers.setContentType(MediaType.APPLICATION_JSON);

        JSONObject requestBody = new JSONObject();
        requestBody.put("programArgs", programArgs);

        HttpEntity<String> request = new HttpEntity<>(requestBody.toString(), headers);

        // Trigger the submitted jar
        ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);

        if (response.getStatusCode() != HttpStatus.OK) {
            LOGGER.error("Job submission failed");
            return "Job submission failed";
        }

        LOGGER.info("Job triggered: {}", response.getBody());
        return response.getBody();
    }

    private String getFileExtension(String filePath) {
        int dotIndex = filePath.lastIndexOf('.');
        if (dotIndex > 0 && dotIndex < filePath.length() - 1) {
            return filePath.substring(dotIndex);
        }
        return null;
    }
}

KafkaConsumer.java:
@Service
public class KafkaConsumer {

    private static final Logger LOGGER = LoggerFactory.getLogger(KafkaConsumer.class);

    @Autowired
    private FlinkApiController flinkApiController;

    @Autowired
    private KafkaProducer kafkaProducer;

    @KafkaListener(topics = "3459-COLLECTION-REQUEST-QUEUE", groupId = "custom-data-transformer-client")
    public void consume(SpaceCollector spaceCollector) {
        LOGGER.info("Received Message: {}", spaceCollector);

        String inputFilePath = spaceCollector.getInputFilePath();
        String fileExtension = getFileExtension(inputFilePath);

        if (fileExtension == null) {
            LOGGER.error("Invalid file extension");
            String errorMessage = createErrorMessage(spaceCollector, "Invalid file extension");
            kafkaProducer.sendErrorMessage(errorMessage);
            return;
        }

        if (!validateFile(inputFilePath)) {
            LOGGER.error("File does not exist: {}", inputFilePath);
            String errorMessage = createErrorMessage(spaceCollector, "File does not exist");
            kafkaProducer.sendErrorMessage(errorMessage);
            return;
        }

        String flinkResponse = flinkApiController.triggerJob(spaceCollector);

        if (flinkResponse.equals("Job submission failed")) {
            String errorMessage = createErrorMessage(spaceCollector, "Job submission failed");
            kafkaProducer.sendErrorMessage(errorMessage);
            return;
        }

        LOGGER.info("Flink Response: {}", flinkResponse);
        // Process success message
        // TODO: Implement success message handling
    }

    private String createErrorMessage(SpaceCollector spaceCollector, String errorReason) {
        String fileName = getFileName(spaceCollector.getInputFilePath());
        String dateReceived = getCurrentDate();
        String dateProcessed = getCurrentDate();
        int numberOfRecords = getNumberOfRecords(spaceCollector.getInputFilePath());
        int numberOfRecordsProcessed = 0;
        int numberOfRecordsFailed = 0;
        String jobStatus = "Failed";
        String jobId = "";
        String jarId = "";
        String exceptions = errorReason;

String errorMessage = String.format("%s %s %s %d %d %d %s %s %s",
                fileName, dateReceived, dateProcessed, numberOfRecords, numberOfRecordsProcessed,
                numberOfRecordsFailed, jobStatus, jobId, jarId, exceptions);

        return errorMessage;
    }

    private String getFileExtension(String filePath) {
        int dotIndex = filePath.lastIndexOf('.');
        if (dotIndex > 0 && dotIndex < filePath.length() - 1) {
            return filePath.substring(dotIndex);
        }
        return null;
    }

    private String getFileName(String filePath) {
        int slashIndex = filePath.lastIndexOf('/');
        if (slashIndex >= 0 && slashIndex < filePath.length() - 1) {
            return filePath.substring(slashIndex + 1);
        }
        return filePath;
    }

    private String getCurrentDate() {
        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");
        return sdf.format(new Date());
    }

    private int getNumberOfRecords(String filePath) {
        int count = 0;
        try (BufferedReader reader = new BufferedReader(new FileReader(filePath))) {
            while (reader.readLine() != null) {
                count++;
            }
        } catch (IOException e) {
            LOGGER.error("Error reading file: {}", filePath, e);
        }
        return count;
    }

    private boolean validateFile(String filePath) {
        File file = new File(filePath);
        return file.exists();
    }
}