To handle job submission failure, you can add an exception handling block around the code for job submission. Here's an updated version of the code that adds the condition for job submission failure:

```java
String jobSubmitUrl = null;

if (programArgs != null && !programArgs.isEmpty()) {
    headers.setContentType(MediaType.APPLICATION_JSON);

    try {
        JSONObject requestBody = new JSONObject();

        if (fileType.equalsIgnoreCase(".csv")) {
            requestBody.put("programArgs", programArgs.replace("input", collector.getInputFilePath()));
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobJarid + "/run";

            // Perform job submission here
            // ...

            // If job submission is successful, set HTTP status code as OK
            HttpStatus status = HttpStatus.OK;

            // Push FileMetadata success message to Kafka topic
            FileMetadata fileMetadata = new FileMetadata();
            // Set fileMetadata properties
            // ...
            kafkaProducer.sendMessage(topicName, fileMetadata.toJson());

        } else {
            // If fileType is not ".csv", set HTTP status code as Not OK
            HttpStatus status = HttpStatus.BAD_REQUEST;

            // Push FileMetadata failure message to Kafka topic
            FileMetadata fileMetadata = new FileMetadata();
            // Set fileMetadata properties for job submission failure
            // ...
            kafkaProducer.sendMessage(topicName, fileMetadata.toJson());
        }

    } catch (Exception e) {
        // Handle job submission failure

        // Set HTTP status code as Not OK
        HttpStatus status = HttpStatus.INTERNAL_SERVER_ERROR;

        // Push FileMetadata failure message to Kafka topic
        FileMetadata fileMetadata = new FileMetadata();
        // Set fileMetadata properties for job submission failure
        // ...
        kafkaProducer.sendMessage(topicName, fileMetadata.toJson());
    }
}
```

Please note that you need to replace the comments with the actual code for job submission and setting the properties of the `FileMetadata` object.

This code sets the HTTP status code as `OK` when the job submission is successful, and as `Not OK` when the job submission fails. It pushes the appropriate `FileMetadata` message (success or failure) to the specified Kafka topic.











--------------------------+---
public String triggerJob(SpaceCollector collector, String fileType) {
    RestTemplate restTemplate = new RestTemplate();
    LOGGER.info("TRIGGER JOB::::");
    HttpHeaders headers = new HttpHeaders();
    HttpEntity<String> request = null;
    String jobSubmitUrl = null; 
    
    if(programArgs != null && !programArgs.isEmpty()) {
        headers.setContentType(MediaType.APPLICATION_JSON);

        JSONObject requestBody = new JSONObject();

        if(fileType.equalsIgnoreCase(".csv")) {
            requestBody.put("programArgs", programArgs.replace("input", collector.getInputFilePath())); 
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobJarid + "/run";
        } else {
            // Handle the failure scenario
            // Populate the FileMetadata with failure details
            FileMetadata fileMetadata = new FileMetadata();
            fileMetadata.setFile_name(collector.getInputFilePath());
            fileMetadata.setDate_received(new Date()); // Set date received
            fileMetadata.setJob_status("job submission failed");
            fileMetadata.setNo_of_records_processed(0); // Assuming no records are processed
            
            // Add stack trace details to the exceptions field of fileMetadata
            fileMetadata.setExceptions("Stack trace details of the failure");
            
            // Send failure message to the audit queue
            kafkaProducer.sendFileMetadataToAuditQueue(fileMetadata, "COLLECTION-AUDIT-QUEUE");
            
            // Further validation can be added here
            // Validate the failure message according to the acceptance criteria
        }
    } else {
        // Handle the scenario if programArgs is null or empty
        // Populate the FileMetadata with failure details
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name(collector.getInputFilePath());
        fileMetadata.setDate_received(new Date()); // Set date received
        fileMetadata.setDate_processed(new Date()); // Set date processed
        fileMetadata.setNo_of_records_in_the_file(0); // Set number of records in the file
        fileMetadata.setNo_of_records_processed(0); // Set number of records processed
        fileMetadata.setNo_of_records_failed(0); // Set number of records failed
        fileMetadata.setJob_status("job submission failed");
        
        // Add stack trace details to the exceptions field of fileMetadata
        fileMetadata.setExceptions("Stack trace details of the failure");
        
        // Send failure message to the audit queue
        kafkaProducer.sendFileMetadataToAuditQueue(fileMetadata, "COLLECTION-AUDIT-QUEUE");
        
        // Further validation can be added here
        // Validate the failure message according to the acceptance criteria
    }

    // Along with the rest of the code
}