To add code for the mentioned acceptance criteria, you can modify the FlinkApiController class as follows:

AC1: The job submission throws error and status code received is Not OK.

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    // Trigger the submitted jar
    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);

    if (response != null && !response.getStatusCode().equals(HttpStatus.OK)) {
        LOGGER.info("Not OK!!");
        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(collector, fileType, response, destinationFolderPath);
    }
    // Rest of the code
}
```

AC2: Publishing to the queue 3459-COLLECTION-AUDIT-QUEUE fails

```java
public void sendFailureMessage(SpaceCollector message, String fileType, ResponseEntity<String> response) {
    // Rest of the code
    
    try {
        kafkaTemplate.send(topicName, metadata);
        LOGGER.info(String.format("Failure message sent %s", metadata));
    } catch (Exception e) {
        LOGGER.error("Failed to publish failure message to audit queue: {}", e.getMessage());
        writeLogToFile(metadata, destinationFolderPath);
    }
    
    // Rest of the code
}
```

AC3: Input file is present and input topic 3459-COLLECTION-REQUEST-QUEUE' is not accessible.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (collector.getInputFilePath() == null || collector.getInputFilePath().isEmpty() || collector.getInputFilePath().isBlank()) {
        LOGGER.info("File doesn't exist::");
        FileMetadata metadata = createFailureMetadata(collector, null, "File does not exist");
        kafkaProducer.sendFailureMessage(collector, null, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}
```

AC4: Jar file is not uploaded to flink cluster.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarFilePresent()) {
        LOGGER.info("No jar files found on the flink cluster");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "No jar files found on the flink cluster");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}

private boolean isJarFilePresent() {
    // Logic to check if jar files are present on the flink cluster
    // Return true if jar files are present, false otherwise
}
```

AC5: Non-existent jar id passed to flink cluster.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarIdValid(flinkJobXmlJarid)) {
        LOGGER.info("Invalid jar id passed");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "Invalid jar id passed");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}

private boolean isJarIdValid(String jarId) {
    // Logic to check if the jar id exists on the flink cluster
    // Return true if jar id is valid, false otherwise
}
```

Note: You may need to modify the code according to your specific application and requirements.


Sure! Here's the updated code with the logic to check if the jar id exists on the Flink cluster and the logic to check if jar files are present:

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarIdValid(flinkJobXmlJarid)) {
        LOGGER.info("Invalid jar id passed");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "Invalid jar id passed");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    } else if (!isJarFilePresent()) {
        LOGGER.info("No jar files found on the Flink cluster");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "No jar files found on the Flink cluster");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }

    // Rest of the code
}

private boolean isJarIdValid(String jarId) {
    // Logic to check if the jar id exists on the Flink cluster
    List<String> jarIds = getJarIdsFromCluster();
    return jarIds.contains(jarId);
}

private boolean isJarFilePresent() {
    // Logic to check if jar files are present on the Flink cluster
    List<String> jarFiles = getJarFilesFromCluster();
    return !jarFiles.isEmpty();
}

private List<String> getJarIdsFromCluster() {
    // Logic to retrieve the list of jar ids from the Flink cluster
    // Return the list of jar ids
}

private List<String> getJarFilesFromCluster() {
    // Logic to retrieve the list of jar files from the Flink cluster
    // Return the list of jar files
}
```

Please note that the methods `getJarIdsFromCluster()` and `getJarFilesFromCluster()` should be implemented based on how you retrieve the jar ids and jar files from the Flink cluster.