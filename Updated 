public String triggerJob(SpaceCollector collector, String fileType) {
    RestTemplate restTemplate = new RestTemplate();
    LOGGER.info("TRIGGER JOB::::");
    HttpHeaders headers = new HttpHeaders();
    HttpEntity<String> request = null;
    String jobSubmitUrl = null; 
    
    if(programArgs != null && !programArgs.isEmpty()) {
        headers.setContentType(MediaType.APPLICATION_JSON);

        JSONObject requestBody = new JSONObject();

        if(fileType.equalsIgnoreCase(".csv")) {
            requestBody.put("programArgs", programArgs.replace("input", collector.getInputFilePath())); 
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobJarid + "/run";
        } else {
            // Handle the failure scenario
            // Populate the FileMetadata with failure details
            FileMetadata fileMetadata = new FileMetadata();
            fileMetadata.setFile_name(collector.getInputFilePath());
            fileMetadata.setDate_received(new Date()); // Set date received
            fileMetadata.setJob_status("job submission failed");
            fileMetadata.setNo_of_records_processed(0); // Assuming no records are processed
            
            // Add stack trace details to the exceptions field of fileMetadata
            fileMetadata.setExceptions("Stack trace details of the failure");
            
            // Send failure message to the audit queue
            kafkaProducer.sendFileMetadataToAuditQueue(fileMetadata, "COLLECTION-AUDIT-QUEUE");
            
            // Further validation can be added here
            // Validate the failure message according to the acceptance criteria
        }
    } else {
        // Handle the scenario if programArgs is null or empty
        // Populate the FileMetadata with failure details
        FileMetadata fileMetadata = new FileMetadata();
        fileMetadata.setFile_name(collector.getInputFilePath());
        fileMetadata.setDate_received(new Date()); // Set date received
        fileMetadata.setDate_processed(new Date()); // Set date processed
        fileMetadata.setNo_of_records_in_the_file(0); // Set number of records in the file
        fileMetadata.setNo_of_records_processed(0); // Set number of records processed
        fileMetadata.setNo_of_records_failed(0); // Set number of records failed
        fileMetadata.setJob_status("job submission failed");
        
        // Add stack trace details to the exceptions field of fileMetadata
        fileMetadata.setExceptions("Stack trace details of the failure");
        
        // Send failure message to the audit queue
        kafkaProducer.sendFileMetadataToAuditQueue(fileMetadata, "COLLECTION-AUDIT-QUEUE");
        
        // Further validation can be added here
        // Validate the failure message according to the acceptance criteria
    }

    // Along with the rest of the code
}