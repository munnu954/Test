import org.apache.flink.api.java.utils.ParameterTool;
import org.apache.flink.client.program.ProgramInvocationException;
import org.apache.flink.client.program.rest.RestClusterClient;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.configuration.RestOptions;
import org.apache.flink.core.execution.JobClient;
import org.apache.flink.runtime.jobgraph.JobGraph;
import org.apache.flink.runtime.jobgraph.JobStatus;
import org.junit.Assert;
import org.junit.Test;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutionException;

public class FlinkJobTest {

@Test
public void testFlinkJobExecution() {
String jarID = "myJob.jar";
String requestURL = "http://localhost:8081/jars/" + jarID + "/run";
String[] programArgs = {"--input", "inputFile.txt", "--bootstrapServer", "localhost:9092", "--topic", "myTopic"};

try {
// create a REST cluster client to connect to the Flink cluster
Configuration config = new Configuration();
config.setInteger(RestOptions.PORT, 8081);
RestClusterClient client = new RestClusterClient
// create a JobGraph from the uploaded job jar
JobGraph jobGraph = client.getJobGraph(jarID);

// set the program arguments as job parameters
ParameterTool params = ParameterTool.fromArgs(programArgs);
jobGraph.getJobConfiguration().setGlobalJobParameters(params);

// submit the job to the Flink cluster
JobClient jobClient = client.submitJob(jobGraph);

// wait for the job to complete
CompletableFuture jobStatusFuture = jobClient.getJobStatus();
JobStatus jobStatus = jobStatusFuture.get();
Assert.assertEquals(JobStatus.FINISHED, jobStatus);

// clean up by canceling the job and closing the client
jobClient.cancel();
client.close();
} catch (ProgramInvocationException | InterruptedException | ExecutionException e) {
e.printStackTrace();
Assert.fail("Failed to execute Flink job: " + e.getMessage());
}
}
}