Apologies for the confusion in the previous response. It seems there was a typo in the import statement. 

Assuming the correct import statement is "import org.joda.time.DateTime;", here is an example of payload data in JSON format:

{
  "date_received": "2021-10-15T10:30:00.000Z",
  "date_processed": "2021-10-16T08:45:30.000Z"
}

In the above payload, "date_received" and "date_processed" fields are represented as strings. The timestamp format follows the ISO 8601 format, and the "Z" at the end indicates that the timestamps are in UTC timezone. The correct import statement is used for the DateTime class from the Joda-Time library.


Sure! Here is an example of how you can pass the payload for the above fields in JSON format:

```json
{
  "inputFilePath": "/path/to/inputFile.txt",
  "url": "https://example.com",
  "port": 8080,
  "outputFilePath": "/path/to/outputFile.txt",
  "delimiters": ",",
  "fileType": "csv",
  "date_received": "2022-03-15T10:30:00Z",
  "no_of_records_in_the_file": 1000,
  "no_of_records_processed": 950,
  "no_of_records_failed": 50,
  "job_id": "69681d91-a9f9-4ae0-a8a7-108bc1199043",
  "jar_id": "6823c1cc-0dec-4a55-ac0e-aeeb7babea18",
  "exceptions": [
    "Exception 1",
    "Exception 2"
  ],
  "collector_id": "ce76c9c7-8a52-4fad-8f32-6387b7e4a051",
  "job_status": "IN_PROGRESS"
}
```

Note: You may need to adjust the values of the above fields based on your specific requirements.







@PostMapping
public String triggerJob(UnifiedAuditMessage auditMsg, String fileType) {

    RestTemplate restTemplate = new RestTemplate();
    LOGGER.info("TRIGGER JOB::::");
    HttpHeaders headers = new HttpHeaders();
    HttpEntity<String> request = null;
    String jobSubmitUrl = null;
  
    if (fileType != null) {
        JSONObject requestBody = new JSONObject();
        headers.setContentType(MediaType.APPLICATION_JSON);

        String programArgs = "";
        if (fileType.equalsIgnoreCase(".csv")) {
            programArgs = "input " + auditMsg.getInputFilePath() + " --path " + auditMsg.getInputFilePath() + " -fileType csv_GIGAMON --bootstarpServer localhost:9092 --auditTopic 3459-DEV-COLLECTION-AUDIT-QUEUE --outputTopic COLLECTION-OUTPUT";
            requestBody.put("programArgs", programArgs);
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobJarid + "/run";
        } else if (fileType.equalsIgnoreCase(".xml")) {
            LOGGER.info("XML FLINK TRIGGER::");
            programArgs = "--filePath " + auditMsg.getInputFilePath() + " --primaryKey |primaryKey| --bootstarpServer localhost:9092 --auditTopic 3459-DEV-COLLECTION-AUDIT-QUEUE --dataTopic COLLECTION-TOPIC";
            requestBody.put("programArgs", programArgs);
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobXmlJarid + "/run";
            LOGGER.info("jobSubmitUrl:" + jobSubmitUrl);
            LOGGER.info("requestBody::" + requestBody.toString());
        } else if (fileType.equalsIgnoreCase(".txt")) {
            LOGGER.info("TEXT FLINK TRIGGER::");
            programArgs = "--input " + auditMsg.getInputFilePath() + " path " + auditMsg.getInputFilePath() + " --bootstarpServer localhost:9092 --auditTopic 3459-DEV-COLLECTION-AUDIT-QUEUE --dataTopic COLLECTION-TOPIC";
            requestBody.put("programArgs", programArgs);
            jobSubmitUrl = flinkApiUrl + "/jars/" + flinkJobtxtJarid + "/run";
        }

        request = new HttpEntity<>(requestBody.toString(), headers);
    }

    // Trigger the submitted jar
    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response: {}", response);
}