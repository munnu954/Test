import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.util.Collector;
import org.json.JSONObject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collection;

public class CsvtoJsonMFCnTransformer extends RichFlatMapFunction<Tuple2<String, CollectionAudit>, Tuple2<JSONObject, CollectionAudit>> {
    private static final Logger LOGGER = LoggerFactory.getLogger(CsTransformerJob.class);
    private String[] headers;
    private IntCounter successIntCounter = new IntCounter();
    private IntCounter failureIntCounter = new IntCounter();

    public CsvtoJsonMFCnTransformer() {}

    @Override
    public void open(Configuration parameters) throws Exception {
        getRuntimeContext().addAccumulator("successIntCounter", this.successIntCounter);
        getRuntimeContext().addAccumulator("failureIntCounter", this.failureIntCounter);
    }

    @Override
    public void flatMap(Tuple2<String, CollectionAudit> tupleValue, Collector<Tuple2<JSONObject, CollectionAudit>> out) throws Exception {
        CollectionAudit message = tupleValue.f1;
        String csvContent = tupleValue.f0;
        String filePath = message.getInputFilePath();
        String fileType = message.getFileType();
        String[] pathArr = filePath.split("/");
        
        if (message != null && csvContent != null) {
            String[] lines = csvContent.split(System.lineSeparator());
            String systemIdLine = lines[0];
            String nodeIpLine = lines[1];
            // More processing...
            
            for (int i = 3; i < lines.length; i++) {
                String str = lines[i];
                String[] arr = str.split(",");
                if (headers == null || headers.length != arr.length) {
                    this.failureIntCounter.add(1);
                    continue;
                }
                JSONObject obj = new JSONObject();
                obj.put("#SystemId", systemId);
                obj.put("#NodeIP", nodeIp);
                // Add FILENAME to JSONOBJECT
                obj.put("FILENAME", fileName);
                for (int j = 0; j < arr.length; j++) {
                    // Add logic to put key-value pairs in obj
                }
                this.successIntCounter.add(1);
                out.collect(Tuple2.of(obj, message));
            }
            LOGGER.info("Completed CSV to JSON transformation");
        } catch (Exception e) {
            LOGGER.error("Error while trying to transform from CSV to JSON {}", e);
            pubAuditMsg.publishFlinkConversionStatus(message, null, JobStatus.FLINK_JOB_FAILED);
        }
    }

    public Integer getSuccessIntCounter() {
        return this.successIntCounter.getLocalValue();
    }

    public Integer getFailureIntCounter() {
        return this.failureIntCounter.getLocalValue();
    }
}
