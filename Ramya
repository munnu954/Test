import org.apache.flink.api.common.accumulators.IntCounter;
import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.util.Collector;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.json.JSONObject;

public class CsvToJsonMRFCnTransformer extends RichFlatMapFunction<Tuple2<String, CollectionAudit>, Tuple2<JSONObject, CollectionAudit>> {
    private static final Logger LOGGER = LoggerFactory.getLogger(CsvToJsonMRFCnTransformer.class);
    
    private final String fileName;
    private String[] headers;
    private final IntCounter successIntCounter = new IntCounter();
    private final IntCounter failureIntCounter = new IntCounter();
    private final PublishAuditMessage pubAuditMsg = new PublishAuditMessage();

    public CsvToJsonMRFCnTransformer(String fileName) {
        this.fileName = fileName;
    }

    @Override
    public void open(Configuration parameters) throws Exception {
        getRuntimeContext().addAccumulator("successIntCounter", this.successIntCounter);
        getRuntimeContext().addAccumulator("failureIntCounter", this.failureIntCounter);
    }

    @Override
    public void flatMap(Tuple2<String, CollectionAudit> tupleValue, Collector<Tuple2<JSONObject, CollectionAudit>> out) {
        CollectionAudit message = tupleValue.f1;
        String csvContent = tupleValue.f0;

        try {
            if (message != null && csvContent != null) {
                String[] lines = csvContent.split(System.lineSeparator());
                if (lines.length < 3) {
                    throw new IllegalArgumentException("Invalid CSV format");
                }
                
                String systemId = extractValue(lines[0], "=");
                String nodeIp = extractValue(lines[1], ":");
                headers = lines[2].split(",");

                for (int i = 3; i < lines.length; i++) {
                    String line = lines[i];
                    String[] values = line.split(",");

                    if (headers.length != values.length) {
                        this.failureIntCounter.add(1);
                        continue;
                    }

                    JSONObject json = new JSONObject();
                    json.put("SystemId", systemId);
                    json.put("NodeIP", nodeIp);
                    json.put("FILENAME", fileName);

                    for (int j = 0; j < headers.length; j++) {
                        String key = headers[j].trim().replace("\"", "");
                        String value = values[j].trim().replace("\"", "");
                        json.put(key, value);
                    }

                    this.successIntCounter.add(1);
                    out.collect(Tuple2.of(json, message));
                }
            }
        } catch (Exception e) {
            LOGGER.error("Error while trying to transform from CSV to JSON", e);
            pubAuditMsg.publishFlinkConversionStatus(message, null, JobStatus.FLINK_JOB_FAILED);
        }
    }

    private String extractValue(String line, String delimiter) {
        int index = line.indexOf(delimiter);
        if (index == -1) {
            throw new IllegalArgumentException("Invalid format: " + line);
        }
        return line.substring(index + 1).trim();
    }
}
