To add code for the given acceptance criteria (AC1-AC5), you can modify the existing code in KafkaProducer.java and FlinkApiController.java classes as follows:

AC1: The job submission throws an error and the status code received is Not OK.

Update the `triggerJob` method in FlinkApiController.java:

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code...

    // Trigger the submitted jar
    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);
    if (response != null && !response.getStatusCode().is2xxSuccessful()) {
        LOGGER.error("Job submission failed. Status code: {}", response.getStatusCodeValue());

        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response);
        writeLogToFile(metadata, destinationFolderPath);

        return "Job triggered: Failure";
    }

    // Rest of the code...
}
```

AC2: Publishing to the queue `3459-COLLECTION-AUDIT-QUEUE` fails.

Update the `sendFailureMessage` method in KafkaProducer.java:

```java
public void sendFailureMessage(SpaceCollector message, String fileType, ResponseEntity response) {
    // Rest of the code...

    this.writeMessage(metadata);
    kafkaProducer.sendToAuditQueue(metadata); // Add this line to send failure message to audit queue
}
```

AC3: Input file is present and input topic `3459-COLLECTION-REQUEST-QUEUE` is not accessible.

Update the `triggerJob` method in FlinkApiController.java:

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code...

    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);
    if (response.getStatusCode().is5xxServerError()) {
        LOGGER.error("Job submission failed. Status code: {}", response.getStatusCodeValue());

        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response);
        writeLogToFile(metadata, destinationFolderPath);

        // Also write to log file and send to audit queue
        writeLogToFile(collector, fileType, response, destinationFolderPath);
        kafkaProducer.sendToAuditQueue(metadata);

        return "Job triggered: Failure";
    }

    // Rest of the code...
}
```

AC4: Jar file is not uploaded to the Flink cluster.

Update the `triggerJob` method in FlinkApiController.java:

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code...

    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);
    if (response.getStatusCode().is5xxServerError()) {
        LOGGER.error("Job submission failed. Status code: {}", response.getStatusCodeValue());

        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response);
        writeLogToFile(metadata, destinationFolderPath);

        // Also write to log file and send to audit queue
        writeLogToFile(collector, fileType, response, destinationFolderPath);
        kafkaProducer.sendToAuditQueue(metadata);

        return "Job triggered: Failure";
    }

    // Rest of the code...
}
```

AC5: Non-existent jar ID passed to the Flink cluster.

Update the `triggerJob` method in FlinkApiController.java:

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code...

    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);
    if (response.getStatusCode().is4xxClientError()) {
        LOGGER.error("Job submission failed. Status code: {}", response.getStatusCodeValue());

        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response);
        writeLogToFile(metadata, destinationFolderPath);

        // Also write to log file and send to audit queue
        writeLogToFile(collector, fileType, response, destinationFolderPath);
        kafkaProducer.sendToAuditQueue(metadata);

        return "Job triggered: Failure";
    }

    // Rest of the code...
}
```

Note: You will need to update the `sendToAuditQueue` method in the KafkaProducer class to send the failure message to the audit queue. Additionally, you need to handle the exceptions and add appropriate error handling in the code.

















---------------------++++++++7++++++(

To add code for the mentioned acceptance criteria, you can modify the FlinkApiController class as follows:

AC1: The job submission throws error and status code received is Not OK.

```java
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    // Trigger the submitted jar
    ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
    LOGGER.info("response::::" + response);

    if (response != null && !response.getStatusCode().equals(HttpStatus.OK)) {
        LOGGER.info("Not OK!!");
        FileMetadata metadata = createFailureMetadata(collector, fileType, response);
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(collector, fileType, response, destinationFolderPath);
    }
    // Rest of the code
}
```

AC2: Publishing to the queue 3459-COLLECTION-AUDIT-QUEUE fails

```java
public void sendFailureMessage(SpaceCollector message, String fileType, ResponseEntity<String> response) {
    // Rest of the code
    
    try {
        kafkaTemplate.send(topicName, metadata);
        LOGGER.info(String.format("Failure message sent %s", metadata));
    } catch (Exception e) {
        LOGGER.error("Failed to publish failure message to audit queue: {}", e.getMessage());
        writeLogToFile(metadata, destinationFolderPath);
    }
    
    // Rest of the code
}
```

AC3: Input file is present and input topic 3459-COLLECTION-REQUEST-QUEUE' is not accessible.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (collector.getInputFilePath() == null || collector.getInputFilePath().isEmpty() || collector.getInputFilePath().isBlank()) {
        LOGGER.info("File doesn't exist::");
        FileMetadata metadata = createFailureMetadata(collector, null, "File does not exist");
        kafkaProducer.sendFailureMessage(collector, null, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}
```

AC4: Jar file is not uploaded to flink cluster.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarFilePresent()) {
        LOGGER.info("No jar files found on the flink cluster");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "No jar files found on the flink cluster");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}

private boolean isJarFilePresent() {
    // Logic to check if jar files are present on the flink cluster
    // Return true if jar files are present, false otherwise
}
```

AC5: Non-existent jar id passed to flink cluster.

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarIdValid(flinkJobXmlJarid)) {
        LOGGER.info("Invalid jar id passed");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "Invalid jar id passed");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }
    // Rest of the code
}

private boolean isJarIdValid(String jarId) {
    // Logic to check if the jar id exists on the flink cluster
    // Return true if jar id is valid, false otherwise
}
```

Note: You may need to modify the code according to your specific application and requirements.


Sure! Here's the updated code with the logic to check if the jar id exists on the Flink cluster and the logic to check if jar files are present:

```java
@PostMapping
public String triggerJob(SpaceCollector collector, String fileType) {
    // Rest of the code
    
    if (!isJarIdValid(flinkJobXmlJarid)) {
        LOGGER.info("Invalid jar id passed");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "Invalid jar id passed");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    } else if (!isJarFilePresent()) {
        LOGGER.info("No jar files found on the Flink cluster");
        FileMetadata metadata = createFailureMetadata(collector, fileType, "No jar files found on the Flink cluster");
        kafkaProducer.sendFailureMessage(collector, fileType, response.toString());
        writeLogToFile(metadata, destinationFolderPath);
    }

    // Rest of the code
}

private boolean isJarIdValid(String jarId) {
    // Logic to check if the jar id exists on the Flink cluster
    List<String> jarIds = getJarIdsFromCluster();
    return jarIds.contains(jarId);
}

private boolean isJarFilePresent() {
    // Logic to check if jar files are present on the Flink cluster
    List<String> jarFiles = getJarFilesFromCluster();
    return !jarFiles.isEmpty();
}

private List<String> getJarIdsFromCluster() {
    // Logic to retrieve the list of jar ids from the Flink cluster
    // Return the list of jar ids
}

private List<String> getJarFilesFromCluster() {
    // Logic to retrieve the list of jar files from the Flink cluster
    // Return the list of jar files
}
```

Please note that the methods `getJarIdsFromCluster()` and `getJarFilesFromCluster()` should be implemented based on how you retrieve the jar ids and jar files from the Flink cluster.