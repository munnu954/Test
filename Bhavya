@Test
public void testSuccessfulTransformationJobSubmission() {
    // Given
    UnifiedAuditMessage auditMsg = new UnifiedAuditMessage();
    auditMsg.setJobStatus(JobStatus.FLINK_JOB_SUBMITTED.toString());
    String jobID = "12345";
    when(jobIDNode.asText()).thenReturn(jobID);
    
    // When
    customDataTransformerClient.transformJobSubmissionSuccess(auditMsg, jobIDNode);
    
    // Then
    verify(kafkaProducer).publishNewFormatAuditMessage(auditMsg, "3459-DEV-COLLECTION-AUDIT-QUEUE");
    verify(logger).info("jobID::" + jobID);
}
@Test
public void testFailedTransformationJobSubmission() {
    // Given
    UnifiedAuditMessage auditMsg = new UnifiedAuditMessage();
    auditMsg.setJobStatus(JobStatus.FLINK_JOB_FAILED.toString());
    String jobID = null;
    when(jobIDNode.asText()).thenReturn(jobID);
    
    // When
    customDataTransformerClient.transformJobSubmissionFailure(auditMsg, jobIDNode);
    
    // Then
    verify(kafkaProducer).publishNewFormatAuditMessage(auditMsg, "3459-DEV-COLLECTION-AUDIT-QUEUE");
    verify(logger).error("Error triggering job", null);
    verify(kafkaConsumer).logAuditData(auditMsg, fileType, null);
    verify(kafkaAuditProducer).createMessageAndLog(auditMsg.getInputFilePath(), auditMsg.getUrl(), auditMsg.getPort(),
        auditMsg.getOutputFilePath(), auditMsg.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()),
        auditMsg.getNo_of_records_in_the_file(), auditMsg.getNo_of_records_processed(), auditMsg.getNo_of_records_failed(), auditMsg.getJob_id(), auditMsg.getJar_id(), auditMsg.getCollector_id(), auditMsg.getExceptions());
    verify(kafkaConsumer).writeLogToFile(auditData, logFolderPath);
}
