Certainly! To extract and parse the jobID value from the response body and pass it to the updateJobStatus function, you can modify the code as follows:

//Trigger the submitted jar
ResponseEntity<String> response = restTemplate.postForEntity(jobSubmitUrl, request, String.class);
LOGGER.info("response: {}", response.getBody());

if (response != null && response.getStatusCode() != HttpStatus.OK) {
    return "Job submitted";
} else {
    LOGGER.info("Not Ok!!");
    UnifiedAuditMessage auditData = kafkaConsumer.logMetadata(auditMsg, fileType, response);

    // Extract and parse the jobID value from the response body
    ObjectMapper objectMapper = new ObjectMapper();
    JsonNode responseBody = objectMapper.readTree(response.getBody());
    String jobID = responseBody.get("jobID").asText();

    // Pass the jobID value to the updateJobStatus function
    updateJobStatus(auditMsg, jobID);

    kafkaAuditProducer.createMessageAndLog(auditMsg.getInputFilePath(), auditMsg.getUrl(), auditMsg.getPort(),
            auditMsg.getOutputFilePath(), auditMsg.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()),
            auditMsg.getNo_of_records_in_the_file(), auditMsg.getNo_of_records_processed(), auditMsg.getNo_of_records_failed(), auditMsg.getJob_id(), auditMsg.getJar_id(), auditMsg.getCollector_id(), auditMsg.getExceptions());
    kafkaConsumer.writeLogToFile(auditMsg, fileType, response, logFolderPath);
}


And then modify the updateJobStatus function to accept the jobID parameter:

private void updateJobStatus(UnifiedAuditMessage auditMsg, String jobID) {
    try {
        RestTemplate restTemplate = new RestTemplate();
        JsonNode jsonNode = restTemplate.getForObject(flinkApiUrl + jobID, JsonNode.class);
        // Rest of the code...
    } catch (Exception e) {
        LOGGER.error("Error updating job status", e.getMessage());
    }
}


By doing this, you can extract the jobID value from the response body and pass it to the updateJobStatus function for further processing.