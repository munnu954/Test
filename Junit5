public void sendMessage(SpaceCollector collector, String fileType, ResponseEntity response, boolean isSuccess) {
    UnifiedAuditMessage metadata = new UnifiedAuditMessage();
    metadata.setFile_name(collector.getInputFilePath());
    metadata.setDate_received(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()));
    metadata.setDate_processed(isSuccess ? new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()) : "");
    metadata.setNo_of_records_in_the_file(0);
    metadata.setNo_of_records_processed(0);
    metadata.setNo_of_records_failed(0);
    metadata.setJob_status(isSuccess ? "JOB SUBMISSION IS SUCCESS" : "FAILURE");
    metadata.setJob_id("");
    metadata.setJar_id("");
    metadata.setExceptions(response.getStatusCode().toString());
    Logger.info(String.format("%s message sent %s", isSuccess ? "Success" : "Failure", metadata));
    this.writeMessage(metadata);
}

public void sendExceptionFailureMessage(SpaceCollector collector, String fileType, Exception e) {
    UnifiedAuditMessage metadata = new UnifiedAuditMessage();
    metadata.setFile_name(collector.getInputFilePath());
    metadata.setDate_received(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()));
    metadata.setDate_processed("");
    metadata.setNo_of_records_in_the_file(0);
    metadata.setNo_of_records_processed(0);
    metadata.setNo_of_records_failed(0);
    metadata.setJob_status("FAILURE");
    metadata.setJob_id("");
    metadata.setJar_id("");
    metadata.setExceptions(e.getMessage());
    Logger.info(String.format("Failure message sent %s", metadata));
    this.writeMessage(metadata);
}

else {
    LOGGER.info("Not Ok!!");
    
    SpaceCollector auditData = kafkaConsumer.logMetadata(collector, fileType, response);
    kafkaAuditProducer.createMessageAndLog(collector.getInputFilePath(), url, port, collector.getOutputFilePath(), collector.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()), auditData.getNo_of_records_in_the_file(), auditData.getNo_of_records_processed(), auditData.getNo_of_records_failed(), auditData.getJob_id(), auditData.getJar_id(), collector.getCollector_id());
    kafkaConsumer.writeLogToFile(collector, fileType, response, logFolderPath);
}

catch (HttpClientErrorException e) {
    e.printStackTrace();
    LOGGER.error("Error triggering job", e.getMessage());
    SpaceCollector auditData = kafkaConsumer.logMetadata(collector, fileType, e);
    kafkaAuditProducer.createMessageAndLog(collector.getInputFilePath(), url, port, collector.getOutputFilePath(), collector.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()), auditData.getNo_of_records_in_the_file(), auditData.getNo_of_records_processed(), auditData.getNo_of_records_failed(), auditData.getJob_id(), auditData.getJar_id(), collector.getCollector_id());
    kafkaConsumer.writeLogToFile(auditData, logFolderPath);
} 

catch (HttpServerErrorException e) {
    e.printStackTrace();
    LOGGER.error("Internal Server Error: 500", e.getMessage());
    SpaceCollector auditData = kafkaConsumer.logMetadata(collector, fileType, e);
    kafkaAuditProducer.createMessageAndLog(collector.getInputFilePath(), url, port, collector.getOutputFilePath(), collector.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()), auditData.getNo_of_records_in_the_file(), auditData.getNo_of_records_processed(), auditData.getNo_of_records_failed(), auditData.getJob_id(), auditData.getJar_id(), collector.getCollector_id());
    kafkaConsumer.writeLogToFile(auditData, logFolderPath);
} 

catch (Exception e) {
    e.printStackTrace();
    LOGGER.error("Error triggering job", e.getMessage());
    SpaceCollector auditData = kafkaConsumer.logMetadata(collector, fileType, e);
    kafkaAuditProducer.createMessageAndLog(collector.getInputFilePath(), url, port, collector.getOutputFilePath(), collector.getDelimiters(), fileType, new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()), auditData.getNo_of_records_in_the_file(), auditData.getNo_of_records_processed(), auditData.getNo_of_records_failed(), auditData.getJob_id(), auditData.getJar_id(), collector.getCollector_id());
    kafkaConsumer.writeLogToFile(auditData, logFolderPath);
}
}