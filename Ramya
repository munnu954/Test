// Existing imports...

public class Main {

    // Existing fields...

    private static CsvDataTransformerUtil util = new CsvDataTransformerUtil();
    private static KafkaPushMessages kafkaPushMessages = new KafkaPushMessages();

    // Existing methods...

    public static void main(String[] args) throws Exception {
        // Existing code...

        try {
            // Existing code...

            if (csvRecords.equals(null) || csvRecords.equals("\r\n")) {
                throw new NullPointerException("No records found");
            }

            // Create a UnifiedAuditMessage instance based on your application logic
            UnifiedAuditMessage auditMessage = new UnifiedAuditMessage(
                UnifiedAuditMessage.ProcessType.TRANSFORMER, // Replace with your process type
                path, // Replace with your input file path
                "example.com", // Replace with your URL
                8080, // Replace with your port
                outputTopic, // Replace with your output file path
                ",", // Replace with your delimiters
                fileType, // Replace with your file type
                UUID.randomUUID(), // Replace with your collector ID
                UnifiedAuditMessage.JobStatus.FLINK_JOB_SUCCESSFUL, // Replace with your job status
                List.of("Exception1", "Exception2"), // Replace with your exceptions list
                new Date(), // Replace with your date received
                new Date(), // Replace with your date processed
                UUID.randomUUID(), // Replace with your job ID
                UUID.randomUUID(), // Replace with your jar ID
                100, // Replace with your number of records in the file
                90, // Replace with your number of records processed
                10 // Replace with your number of records failed
            );

            // Publish the message based on job status
            if (auditMessage.getJobStatus() == UnifiedAuditMessage.JobStatus.FLINK_JOB_SUCCESSFUL) {
                auditMessage.setJobStatus(UnifiedAuditMessage.JobStatus.FLINK_JOB_SUCCESSFUL);
            } else {
                auditMessage.setJobStatus(UnifiedAuditMessage.JobStatus.FLINK_JOB_FAILED);
            }

            // Push the Unified Audit Message to the audit queue
            pushToAuditQueue(auditMessage);

        } catch (Exception e) {
            e.printStackTrace();
            kafkaPushMessages.pushMessageToAuditKafka(path, "No-records found: " + e, "Failed");
            env.execute();
        }
    }

    // Existing methods...

    public static void pushToAuditQueue(UnifiedAuditMessage auditMessage) throws Exception {
        // Push the Unified Audit Message to the audit queue
        kafkaPushMessages.pushToKafka(auditMessage);
        env.execute();
    }
}
